{"id": "a479dfc8-448a-458d-a226-8313dc702c2e", "fitness": 0.02441495703777166, "name": "HybridPSONelderMead", "description": "A hybrid metaheuristic combining a modified Particle Swarm Optimization (PSO) with a local search using Nelder-Mead to enhance exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass HybridPSONelderMead:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy()\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 10, 'maxfev': 10*self.dim})\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info\n", "configspace": "", "generation": 0, "feedback": "The algorithm HybridPSONelderMead got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": [], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07324487111331497]}}
{"id": "fe1b4689-ddb2-43f1-a79a-dcc9721d098e", "fitness": 0.024894745772366073, "name": "EnhancedHybridPSONelderMead", "description": "Enhanced Hybrid PSO-Nelder Mead with adaptive inertia weight for improved convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMead:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy()\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            #Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count/self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 10, 'maxfev': 10*self.dim})\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 1, "feedback": "The algorithm EnhancedHybridPSONelderMead got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.04.", "error": "", "parent_ids": ["a479dfc8-448a-458d-a226-8313dc702c2e"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07468423731709822]}}
{"id": "602f7d88-e34d-4d75-ae8b-657d805dd580", "fitness": 0.024286903307857738, "name": "EnhancedHybridPSONelderMead", "description": "Enhanced Hybrid PSO-Nelder Mead with adaptive inertia weight and increased Nelder-Mead iterations for improved convergence.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMead:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy()\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 20, 'maxfev': 20*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 2, "feedback": "The algorithm EnhancedHybridPSONelderMead got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["a479dfc8-448a-458d-a226-8313dc702c2e"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07286070992357321]}}
{"id": "2433dedd-a003-49d7-b260-5751a7a2b133", "fitness": 0.023943010803891954, "name": "EnhancedHybridPSONelderMeadImproved", "description": "Enhanced Hybrid PSO-Nelder Mead with adaptive inertia weight, increased Nelder-Mead iterations, and population diversification using Cauchy mutation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMeadImproved:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy()\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * 0.1\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 20, 'maxfev': 20*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 3, "feedback": "The algorithm EnhancedHybridPSONelderMeadImproved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["602f7d88-e34d-4d75-ae8b-657d805dd580"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07182903241167586]}}
{"id": "5d6efeae-fef4-408a-8ea8-3e8499107594", "fitness": 0.02328095108002161, "name": "EnhancedHybridPSONelderMeadImprovedV2", "description": "Enhanced Hybrid PSO-Nelder Mead with adaptive inertia weight, increased Nelder-Mead iterations, and population diversification using improved Cauchy mutation and enhanced global best update.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMeadImprovedV2:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * 0.05\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 20, 'maxfev': 20*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 4, "feedback": "The algorithm EnhancedHybridPSONelderMeadImprovedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["2433dedd-a003-49d7-b260-5751a7a2b133"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.06984285324006483]}}
{"id": "5eaead11-4a65-4a3a-a835-9ae5cc4708b8", "fitness": 0.024335381911118056, "name": "EnhancedHybridPSONelderMeadImprovedV3", "description": "Improved Hybrid PSO-Nelder Mead with enhanced Cauchy mutation scaling and dynamic Nelder-Mead iteration control.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMeadImprovedV3:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * 0.02 #Reduced scaling factor\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Dynamic iteration control\n            max_nelder_mead_iter = int(20 + 10 * np.exp(-self.eval_count / self.budget)) # Dynamically reduce iterations\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': max_nelder_mead_iter, 'maxfev': max_nelder_mead_iter*self.dim})\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 5, "feedback": "The algorithm EnhancedHybridPSONelderMeadImprovedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5d6efeae-fef4-408a-8ea8-3e8499107594"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07300614573335416]}}
{"id": "6e8ad409-fa3a-494d-94ee-63a08beb334c", "fitness": 0.024122230986881713, "name": "AdaptiveHybridPSONelderMeadImprovedV3", "description": "Adaptive Hybrid PSO-Nelder Mead with improved Cauchy mutation scaling and enhanced global best update, incorporating dynamic population size adjustment.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSONelderMeadImprovedV3:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * 0.02 #Modified scaling factor\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 20, 'maxfev': 20*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 6, "feedback": "The algorithm AdaptiveHybridPSONelderMeadImprovedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5d6efeae-fef4-408a-8ea8-3e8499107594"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07236669296064514]}}
{"id": "2509ac20-2850-4afd-b4be-f8c5327f43a7", "fitness": 0.024730455226146423, "name": "EnhancedHybridPSONelderMeadImprovedV3", "description": "Enhanced Hybrid PSO-Nelder Mead with adaptive inertia weight, increased Nelder-Mead iterations, and population diversification using improved Cauchy mutation and enhanced global best update, and improved initial population diversification.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMeadImprovedV3:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds + 0.1*(self.upper_bounds - self.lower_bounds), self.upper_bounds - 0.1*(self.upper_bounds - self.lower_bounds), (self.population_size, self.dim)) #Improved initial population diversification\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * 0.05\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 20, 'maxfev': 20*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 7, "feedback": "The algorithm EnhancedHybridPSONelderMeadImprovedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5d6efeae-fef4-408a-8ea8-3e8499107594"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07419136567843927]}}
{"id": "4975799b-4180-42a5-9581-37943b8fe165", "fitness": 0.02382349167919778, "name": "EnhancedHybridPSONelderMeadImprovedV3", "description": "Improved Hybrid PSO-Nelder Mead with adaptive inertia weight, increased Nelder-Mead iterations, enhanced Cauchy mutation, and enhanced global best update, and a refined population initialization strategy.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMeadImprovedV3:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim)) #Improved Initialization\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * 0.05\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 20, 'maxfev': 20*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 8, "feedback": "The algorithm EnhancedHybridPSONelderMeadImprovedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5d6efeae-fef4-408a-8ea8-3e8499107594"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07147047503759334]}}
{"id": "d86ecfe8-d53f-485e-a96f-f5e3ed0352d9", "fitness": 0.024703412520078936, "name": "EnhancedHybridPSONelderMeadImprovedV3", "description": "Enhanced Hybrid PSO-Nelder Mead with adaptive inertia weight, increased Nelder-Mead iterations, and population diversification using improved Cauchy mutation, enhanced global best update, and improved exploration via increased Cauchy mutation scale.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMeadImprovedV3:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * 0.1 #Increased scaling factor\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 20, 'maxfev': 20*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 9, "feedback": "The algorithm EnhancedHybridPSONelderMeadImprovedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5d6efeae-fef4-408a-8ea8-3e8499107594"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07411023756023681]}}
{"id": "7c3d2192-7786-4c26-8b91-fc5480e0b998", "fitness": 0.023790357483548973, "name": "EnhancedHybridPSONelderMeadImprovedV3", "description": "Enhanced Hybrid PSO-Nelder Mead with adaptive inertia weight, increased Nelder-Mead iterations, and population diversification using improved Cauchy mutation and enhanced global best update,  incorporating a more robust global best update strategy and refined Cauchy mutation scaling.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMeadImprovedV3:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * 0.02 # Refined scaling\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 20, 'maxfev': 20*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 10, "feedback": "The algorithm EnhancedHybridPSONelderMeadImprovedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5d6efeae-fef4-408a-8ea8-3e8499107594"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07137107245064692]}}
{"id": "0fd476a4-8250-4a23-910f-f587de67d43d", "fitness": 0.023442278133401023, "name": "EnhancedHybridPSONelderMeadImprovedV3", "description": "Hybrid PSO-Nelder-Mead with adaptive inertia weight, enhanced Cauchy mutation, and improved Nelder-Mead termination criteria for efficient global optimization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMeadImprovedV3:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * 0.05\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 30, 'xatol':1e-8, 'fatol':1e-8}) #Increased maxiter and added termination criteria\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 11, "feedback": "The algorithm EnhancedHybridPSONelderMeadImprovedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5d6efeae-fef4-408a-8ea8-3e8499107594"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07032683440020307]}}
{"id": "6ba9408d-0c3f-4821-8f92-370abc6e7c6d", "fitness": 0.02406156798226461, "name": "EnhancedHybridPSONelderMeadImprovedV3", "description": "Enhanced Hybrid PSO-Nelder Mead with adaptive inertia weight, increased Nelder-Mead iterations, and population diversification using improved Cauchy mutation, enhanced global best update, and improved Nelder-Mead initial point selection.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMeadImprovedV3:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * 0.05\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations\n            #Improved Nelder-Mead starting point selection\n            res = minimize(objective_function, personal_bests[np.argmin(personal_best_fitness)], method='Nelder-Mead', options={'maxiter': 20, 'maxfev': 20*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 12, "feedback": "The algorithm EnhancedHybridPSONelderMeadImprovedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5d6efeae-fef4-408a-8ea8-3e8499107594"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07218470394679383]}}
{"id": "59588815-057c-4969-8786-c59f217652aa", "fitness": 0.024157901623742, "name": "EnhancedHybridPSONelderMeadImprovedV3", "description": "Improved Hybrid PSO-Nelder Mead with enhanced Cauchy mutation scaling and increased Nelder-Mead iterations for better exploration and exploitation.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMeadImprovedV3:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * 0.1 #Increased scaling factor\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 30, 'maxfev': 30*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 13, "feedback": "The algorithm EnhancedHybridPSONelderMeadImprovedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5d6efeae-fef4-408a-8ea8-3e8499107594"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07247370487122601]}}
{"id": "482a55cc-9eb5-437b-b26f-799550c680da", "fitness": 0.02349891957350318, "name": "EnhancedHybridPSONelderMeadImprovedV3", "description": "Improved Hybrid PSO-Nelder Mead with adaptive inertia weight, increased Nelder-Mead iterations, enhanced Cauchy mutation, and enhanced global best update, incorporating a more robust Nelder-Mead termination criterion.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMeadImprovedV3:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * 0.05\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations and robust termination\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 20, 'maxfev': 20*self.dim, 'xtol':1e-6}) #Added xtol for robust termination\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 14, "feedback": "The algorithm EnhancedHybridPSONelderMeadImprovedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5d6efeae-fef4-408a-8ea8-3e8499107594"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07049675872050953]}}
{"id": "74514748-e63f-4aa2-8e17-e9b800a90af0", "fitness": 0.024269550562329763, "name": "EnhancedHybridPSONelderMeadImprovedV3", "description": "Enhanced Hybrid PSO-Nelder Mead with adaptive inertia weight, increased Nelder-Mead iterations, and population diversification using improved Cauchy mutation and enhanced global best update, and improved population initialization.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EnhancedHybridPSONelderMeadImprovedV3:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        # Improved initialization: better spread of initial points\n        self.best_solution_overall = (self.upper_bounds + self.lower_bounds)/2 + (self.upper_bounds - self.lower_bounds)*np.random.rand(self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * 0.05\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': 20, 'maxfev': 20*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 15, "feedback": "The algorithm EnhancedHybridPSONelderMeadImprovedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5d6efeae-fef4-408a-8ea8-3e8499107594"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07280865168698929]}}
{"id": "0ae7d318-7bbd-41fd-8b4e-e7edead3e382", "fitness": 0.02298456235890625, "name": "AdaptiveHybridPSONelderMeadImprovedV3", "description": "Adaptive Hybrid PSO-Nelder Mead with improved Cauchy mutation, enhanced global best update, and dynamic population sizing.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSONelderMeadImprovedV3:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling and adaptive rate\n            cauchy_mutation_rate = 0.05 * (1 - self.eval_count / self.budget) #Adaptive rate\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * cauchy_mutation_rate\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations and adaptive maxiter\n            nelder_mead_maxiter = int(20 + 10 * (1 - self.eval_count/self.budget)) # Adaptive maxiter\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': nelder_mead_maxiter, 'maxfev': nelder_mead_maxiter*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 16, "feedback": "The algorithm AdaptiveHybridPSONelderMeadImprovedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["5d6efeae-fef4-408a-8ea8-3e8499107594"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.06895368707671874]}}
{"id": "b01664c6-f221-460d-b365-bae6f6f50be1", "fitness": 0.024207637986649214, "name": "AdaptiveHybridPSONelderMeadImprovedV4", "description": "Adaptive Hybrid PSO-Nelder Mead with improved Cauchy mutation, enhanced global best update, and dynamic population sizing, incorporating a more robust global best update strategy.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSONelderMeadImprovedV4:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            #More robust global best update: Check all particles, not just the best of current iteration\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling and adaptive rate\n            cauchy_mutation_rate = 0.05 * (1 - self.eval_count / self.budget) #Adaptive rate\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * cauchy_mutation_rate\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations and adaptive maxiter\n            nelder_mead_maxiter = int(20 + 10 * (1 - self.eval_count/self.budget)) # Adaptive maxiter\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': nelder_mead_maxiter, 'maxfev': nelder_mead_maxiter*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 17, "feedback": "The algorithm AdaptiveHybridPSONelderMeadImprovedV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["0ae7d318-7bbd-41fd-8b4e-e7edead3e382"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07262291395994765]}}
{"id": "37b45a89-5dcf-4239-8fd3-91c4cb33fe22", "fitness": 0.024480712987543826, "name": "AdaptiveHybridPSONelderMeadImprovedV4", "description": "Adaptive Hybrid PSO-Nelder Mead with improved Cauchy mutation, enhanced global best update, dynamic population sizing, and adaptive Nelder-Mead termination.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSONelderMeadImprovedV4:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling and adaptive rate\n            cauchy_mutation_rate = 0.05 * (1 - self.eval_count / self.budget) #Adaptive rate\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * cauchy_mutation_rate\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations and adaptive maxiter\n            nelder_mead_maxiter = int(20 + 10 * (1 - self.eval_count/self.budget)) # Adaptive maxiter\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': nelder_mead_maxiter, 'maxfev': nelder_mead_maxiter*self.dim}) #Increased maxiter and maxfev\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget and (self.budget - self.eval_count) > nelder_mead_maxiter*self.dim * 0.1: #Added termination condition\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 18, "feedback": "The algorithm AdaptiveHybridPSONelderMeadImprovedV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["0ae7d318-7bbd-41fd-8b4e-e7edead3e382"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07344213896263148]}}
{"id": "5d15de60-40b8-4ce5-b250-738526b3d876", "fitness": 0.023749757672737293, "name": "AdaptiveHybridPSONelderMeadImprovedV4", "description": "Adaptive Hybrid PSO-Nelder Mead with improved Cauchy mutation, enhanced global best update, and dynamic population sizing, incorporating a more robust Nelder-Mead termination criterion.", "code": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass AdaptiveHybridPSONelderMeadImprovedV4:\n    def __init__(self, budget: int, dim: int, lower_bounds: list[float], upper_bounds: list[float]):\n        self.budget = int(budget)\n        self.dim = int(dim)\n        self.lower_bounds = np.array(lower_bounds, dtype=float)\n        self.upper_bounds = np.array(upper_bounds, dtype=float)\n\n        self.eval_count = 0\n        self.best_solution_overall = None\n        self.best_fitness_overall = float('inf')\n        self.population_size = 20 # Parameter for PSO\n        self.inertia_weight = 0.7 # PSO parameter\n        self.cognitive_coefficient = 1.4 # PSO parameter\n        self.social_coefficient = 1.4 # PSO parameter\n\n    def optimize(self, objective_function: callable, acceptance_threshold: float = 1e-8) -> tuple:\n        self.eval_count = 0\n        self.best_solution_overall = np.random.uniform(self.lower_bounds, self.upper_bounds, self.dim)\n        self.best_fitness_overall = objective_function(self.best_solution_overall.reshape(1,-1))[0]\n        self.eval_count +=1\n        \n        population = np.random.uniform(self.lower_bounds, self.upper_bounds, (self.population_size, self.dim))\n        velocities = np.zeros((self.population_size, self.dim))\n        personal_bests = population.copy()\n        personal_best_fitness = np.apply_along_axis(lambda x: objective_function(x.reshape(1,-1))[0], 1, population)\n        self.eval_count += self.population_size\n\n        global_best = self.best_solution_overall.copy()\n        \n        while self.eval_count < self.budget:\n            for i in range(self.population_size):\n                if personal_best_fitness[i] < self.best_fitness_overall:\n                    self.best_fitness_overall = personal_best_fitness[i]\n                    self.best_solution_overall = personal_bests[i].copy()\n                    global_best = self.best_solution_overall.copy() # Update global best immediately\n                    \n            r1 = np.random.rand(self.dim)\n            r2 = np.random.rand(self.dim)\n            # Adaptive inertia weight\n            self.inertia_weight = 0.4 + 0.3 * np.exp(-self.eval_count / self.budget)\n            velocities = self.inertia_weight * velocities + self.cognitive_coefficient * r1 * (personal_bests - population) + self.social_coefficient * r2 * (global_best - population)\n            population = population + velocities\n            \n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n            #Cauchy Mutation for diversification - Improved scaling and adaptive rate\n            cauchy_mutation_rate = 0.05 * (1 - self.eval_count / self.budget) #Adaptive rate\n            cauchy_mutation = np.random.standard_cauchy(size=(self.population_size, self.dim)) * (self.upper_bounds - self.lower_bounds) * cauchy_mutation_rate\n            population = population + cauchy_mutation\n            population = np.clip(population, self.lower_bounds, self.upper_bounds)\n\n\n            fitness_values = objective_function(population)\n            self.eval_count += self.population_size\n            \n            for i in range(self.population_size):\n                if fitness_values[i] < personal_best_fitness[i]:\n                    personal_best_fitness[i] = fitness_values[i]\n                    personal_bests[i] = population[i].copy()\n\n\n            #Local search with Nelder-Mead - Increased iterations and adaptive maxiter\n            nelder_mead_maxiter = int(20 + 10 * (1 - self.eval_count/self.budget)) # Adaptive maxiter\n            res = minimize(objective_function, self.best_solution_overall, method='Nelder-Mead', options={'maxiter': nelder_mead_maxiter, 'maxfev': nelder_mead_maxiter*self.dim, 'xatol':1e-10}) #Added xatol for robustness\n            if res.fun < self.best_fitness_overall and self.eval_count + res.nfev <= self.budget:\n                self.best_fitness_overall = res.fun\n                self.best_solution_overall = res.x\n                self.eval_count += res.nfev\n\n        optimization_info = {\n            'function_evaluations_used': self.eval_count,\n            'final_best_fitness': self.best_fitness_overall\n        }\n        return self.best_solution_overall, self.best_fitness_overall, optimization_info", "configspace": "", "generation": 19, "feedback": "The algorithm AdaptiveHybridPSONelderMeadImprovedV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.02 with standard deviation 0.03.", "error": "", "parent_ids": ["0ae7d318-7bbd-41fd-8b4e-e7edead3e382"], "operator": null, "metadata": {"aucs": [0.0, 0.0, 0.07124927301821188]}}
